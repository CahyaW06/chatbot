{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54460ff2",
   "metadata": {},
   "source": [
    "## Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f567d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import redis\n",
    "# redis_client = redis.Redis(host='localhost', port=6379, decode_responses=True)\n",
    "\n",
    "# try:\n",
    "#     r = redis.Redis(host='localhost', port=6379, decode_responses=True)\n",
    "#     r.ping()\n",
    "#     print(\"✅ Redis terkoneksi!\")\n",
    "# except redis.ConnectionError as e:\n",
    "#     print(\"❌ Redis gagal terkoneksi:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa82034e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# hybrid_instance.py\n",
    "\n",
    "import mysql.connector\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from functools import lru_cache\n",
    "\n",
    "chat_memory = {}\n",
    "\n",
    "def load_faq():\n",
    "    conn = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"\",\n",
    "        database=\"chatbot-humas\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"SELECT * FROM pertanyaan\")\n",
    "    faq = cursor.fetchall()\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    return faq\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def get_model(model_name='intfloat/multilingual-e5-small'):\n",
    "    return SentenceTransformer(model_name)\n",
    "\n",
    "def load_cache(session_id):\n",
    "    return chat_memory.get(session_id, [])\n",
    "\n",
    "def load_context(session_id):\n",
    "    history = load_cache(session_id)\n",
    "    return \" \".join([entry[\"query\"] if entry[\"query\"] else \"\" for entry in history])\n",
    "\n",
    "def save_cache(session_id, query, results):\n",
    "    if session_id not in chat_memory:\n",
    "        chat_memory[session_id] = []\n",
    "    chat_memory[session_id].append({\n",
    "        \"query\": query,\n",
    "        \"results\": results\n",
    "    })\n",
    "\n",
    "def clear_cache():\n",
    "    global chat_memory\n",
    "    chat_memory = {}\n",
    "    print('chat_memory has been cleared.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5dff4b",
   "metadata": {},
   "source": [
    "## Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cos_sim\n",
    "# import redis\n",
    "\n",
    "class HybridSearch:\n",
    "    def __init__(self, model_name='intfloat/multilingual-e5-small', top_k=1, redis_host='localhost', redis_port=6379):\n",
    "        self.model = get_model(model_name)\n",
    "        self.top_k = top_k\n",
    "        self.ttl = 28800\n",
    "\n",
    "        # # Redis\n",
    "        # self.redis = redis.Redis(host=redis_host, port=redis_port, decode_responses=True)\n",
    "\n",
    "    def build_index(self, faq):\n",
    "        self.faq_questions = [item[1] for item in faq]\n",
    "        self.faq_answers = [item[2] for item in faq]\n",
    "\n",
    "        self.tfidf_vectorizer = TfidfVectorizer()\n",
    "        self.tfidf_matrix = self.tfidf_vectorizer.fit_transform(self.faq_questions)\n",
    "\n",
    "        self.semantic_embeddings = self.model.encode(self.faq_questions, normalize_embeddings=True)\n",
    "\n",
    "    def search(self, query, session_id=None, use_cache=False):\n",
    "        # # Redis\n",
    "        # if session_id and self.redis_is_on:\n",
    "        #     cached = self.redis.get(f\"faq:{session_id}:{query}\")\n",
    "        #     if cached:\n",
    "        #         return json.loads(cached)\n",
    "\n",
    "        # dict\n",
    "        if session_id:\n",
    "            cached = load_context(session_id) if use_cache is True else \"\"\n",
    "\n",
    "        # Step 1: TF-IDF filter\n",
    "        tfidf_queries = self.preprocess_text(query)  # hanya query baru\n",
    "\n",
    "        best_tfidf_score = 0\n",
    "        best_query = None\n",
    "        best_tfidf_query = None\n",
    "\n",
    "        # Precompute TF-IDF dari cached (memori lama)\n",
    "        cached_score = None\n",
    "        if cached:\n",
    "            cached_tfidf = self.tfidf_vectorizer.transform([cached])\n",
    "            cached_score = cos_sim(cached_tfidf, self.tfidf_matrix)[0]\n",
    "            cached_score *= 0.3  # Bobot 30% dari konteks lama\n",
    "\n",
    "        for paragraph in tfidf_queries:\n",
    "            tfidf_query = self.tfidf_vectorizer.transform([paragraph])\n",
    "            tfidf_scores = cos_sim(tfidf_query, self.tfidf_matrix)[0]\n",
    "\n",
    "            # Bobot tambahan jika ada tanda tanya\n",
    "            tfidf_scores *= 1.2 if self.is_question(paragraph) else tfidf_scores\n",
    "\n",
    "            # Gabungkan skor baru dengan skor lama jika ada\n",
    "            if cached_score is not None:\n",
    "                combined_score = tfidf_scores * 0.7 + cached_score\n",
    "            else:\n",
    "                combined_score = tfidf_scores\n",
    "\n",
    "            highest_score = max(combined_score)\n",
    "            if highest_score > best_tfidf_score:\n",
    "                best_query = paragraph\n",
    "                best_tfidf_score = highest_score\n",
    "                best_tfidf_query = combined_score\n",
    "                print(f\"question: {paragraph}\")\n",
    "                print(f\"related question: {self.faq_questions[np.argmax(combined_score)]}\")\n",
    "                print(f\"score: {highest_score}\")\n",
    "\n",
    "        if best_tfidf_query is None or best_tfidf_score < 0.5:\n",
    "            results = [(best_query, \"\", 0.0)]\n",
    "        else:\n",
    "            top_k_indices = np.argsort(best_tfidf_query)[::-1][:self.top_k]\n",
    "            top_k_faqs = [self.faq_questions[i] for i in top_k_indices]\n",
    "            top_k_answer = [self.faq_answers[i] for i in top_k_indices]\n",
    "\n",
    "            # Step 2: Semantic reranking\n",
    "            query_embedding = self.model.encode([query], normalize_embeddings=True)\n",
    "            selected_embeddings = self.semantic_embeddings[top_k_indices]\n",
    "            semantic_scores = np.dot(query_embedding, selected_embeddings.T)[0]\n",
    "\n",
    "            # Sort top-k by semantic similarity\n",
    "            final_rank = np.argsort(semantic_scores)[::-1]\n",
    "            results = [(top_k_faqs[i], top_k_answer[i], float(semantic_scores[i])) for i in final_rank]\n",
    "\n",
    "        # # Redis\n",
    "        # if session_id and self.redis_is_on:\n",
    "        #     self.redis.setex(f\"faq:{session_id}:{query}\", self.ttl, json.dumps(results))\n",
    "\n",
    "        # dict\n",
    "        if session_id and use_cache is True:\n",
    "            save_cache(session_id, best_query, results)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def preprocess_text(self, text, cached=None):\n",
    "        text = self.cleaning_tanda_baca_berulang(text)\n",
    "        texts = self.spliting_paragraph(text, cached)\n",
    "        processed_texts = []\n",
    "\n",
    "        for text in texts:\n",
    "            text = text.lower()\n",
    "            text = self.append_titik(text)\n",
    "            processed_texts.append(text)\n",
    "\n",
    "        return processed_texts\n",
    "\n",
    "    def cleaning_tanda_baca_berulang(self, text):\n",
    "        return re.sub(r'([!?.;,:\\-\\n])\\1+', r'\\1', text)\n",
    "\n",
    "    def append_titik(self, text):\n",
    "        if not text.endswith(('.', '?', '!')):\n",
    "            return text + '.'\n",
    "        return text\n",
    "\n",
    "    def spliting_paragraph(self, text, cached=None):\n",
    "        paragraph = text.split('\\n')\n",
    "        return paragraph\n",
    "\n",
    "    def is_question(self, text):\n",
    "        if '?' in text:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d32ace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "faq = load_faq()\n",
    "\n",
    "engine = HybridSearch()\n",
    "engine.build_index(faq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c1c23c",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30885da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: selamat siang, apakah ini benar dengan humas uns?\n",
      "related question: Saya ingin bertanya berkaitan dengan website siakad uns yang mengalami masalah\n",
      "score: 0.2739801383071332\n",
      "\n",
      "jawaban: \n",
      "\n",
      "cached: selamat siang, apakah ini benar dengan humas uns?\n",
      "question: saya merupakan mahasiswa asing yang diterima di uns melalui beasiswa internasional. kemudian saya diminta untuk menghubungi international office uns.\n",
      "related question: kontak international office uns\n",
      "score: 0.1684099775963998\n",
      "\n",
      "jawaban: \n",
      "\n",
      "cached: selamat siang, apakah ini benar dengan humas uns? saya merupakan mahasiswa asing yang diterima di uns melalui beasiswa internasional. kemudian saya diminta untuk menghubungi international office uns.\n",
      "question: apakah saya bisa meminta no mereka?\n",
      "related question: pembayaran registrasi calon mahasiswa bisa menghubungi no kontak berapa\n",
      "score: 0.37785646769497655\n",
      "\n",
      "jawaban: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_memory = {}\n",
    "\n",
    "list_pertanyaan = [\n",
    "    \"Selamat siang, apakah ini benar dengan humas uns?\",\n",
    "    \"Saya merupakan mahasiswa asing yang diterima di UNS melalui beasiswa internasional. Kemudian saya diminta untuk menghubungi international office uns.\",\n",
    "    # \"Gimana ya caranya?\",\n",
    "    \"APakah saya bisa meminta no mereka?\",\n",
    "    # \"Kalau saya mengundurkan diri begitu, apakah ada pengembalian dana ya Kak? Terima kasih\",\n",
    "    # \"Terima kasih kak atas jawabannya\"\n",
    "]\n",
    "\n",
    "session_id = '1'\n",
    "for pertanyaan in list_pertanyaan:\n",
    "    results = engine.search(query=pertanyaan, session_id=session_id, use_cache=True)\n",
    "\n",
    "    # print(\"\\nHasil pencarian:\")\n",
    "    # for question, answer, score in results:\n",
    "    #     print(f\"{question} —> {answer} — score: {score:.4f}\")\n",
    "\n",
    "    print(f\"\\njawaban: {results[0][1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3a25f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': [{'query': 'selamat siang, apakah ini benar dengan humas uns?', 'results': [('selamat siang, apakah ini benar dengan humas uns?', '', 0.0)]}, {'query': 'saya merupakan mahasiswa asing yang diterima di uns melalui beasiswa internasional. kemudian saya diminta untuk menghubungi international office uns.', 'results': [('saya merupakan mahasiswa asing yang diterima di uns melalui beasiswa internasional. kemudian saya diminta untuk menghubungi international office uns.', '', 0.0)]}, {'query': 'apakah saya bisa meminta no mereka?', 'results': [('apakah saya bisa meminta no mereka?', '', 0.0)]}]}\n"
     ]
    }
   ],
   "source": [
    "print(chat_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b08da31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selamat siang, apakah ini benar dengan humas uns? saya merupakan mahasiswa asing yang diterima di uns melalui beasiswa internasional. kemudian saya diminta untuk menghubungi international office uns. apakah saya bisa meminta no mereka?\n"
     ]
    }
   ],
   "source": [
    "print(load_context(session_id=session_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
